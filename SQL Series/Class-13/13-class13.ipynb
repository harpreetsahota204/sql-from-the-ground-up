{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Functions, Part 4: Partition By Order By\n",
    "\n",
    "As you may remember, we've covered `PARTITION BY` a few wekes ago in our course, but we never used it with another feature: ORDER BY. \n",
    "\n",
    "Today, we'll use them together to create powerful statistics and show how you can use various functions independently for each group of rows.\n",
    "\n",
    "Access tables via the fiddle here: https://www.db-fiddle.com/f/45nXwRXBKAwt9MsbCHiuxT/1\n",
    "\n",
    "## Exercise\n",
    "Select all the information from the store table.\n",
    "\n",
    "Each store has its own id, country and city. \n",
    "\n",
    "There is only one store per city in our table to make things a bit easier. Apart from that, you can see when the store was opened and what rating it has (1-5), based on customers' opinions.\n",
    "\n",
    "# Exercise\n",
    "Select all the information from the sales table.\n",
    "\n",
    "In this table, the sales results are gathered for each store from the period between August 1 and August 14 2016. \n",
    "\n",
    "You can find the id of the store, the date, and three important values: the total revenue on that day, the number of transactions and the number of customers who entered the store (but not necessarily bought anything).\n",
    "\n",
    "\n",
    "# Scope of this section\n",
    "\n",
    "Before we get down to real work, let's explain what we'll actually teach you today.\n",
    "\n",
    "Earlier you learned what PARTITION BY is. \n",
    "\n",
    "It allows you to compute certain functions independently for groups of rows and still maintain their individual character.\n",
    "\n",
    "Previously, we only used PARTITION BY with the aggregate functions which you had known before: AVG(), COUNT(), MAX(), MIN(), SUM(). \n",
    "\n",
    "None of these functions required the use of ORDER BY: the order of rows simply doesn't matter in this case.\n",
    "\n",
    "However, we got to know new elements where the order does matter: ranking functions, window frames and analytical functions.\n",
    "\n",
    "In this part, I'll teach you how to use PARTITION BY with these new elements. \n",
    "\n",
    "Each time, you will also need an ORDER BY clause – hence the name of the part: PARTITION BY ORDER BY. \n",
    "\n",
    "Remember to keep the order: PARTITION BY comes before ORDER BY, or it simply won't make any sense.\n",
    "\n",
    "# PARTITION BY – refresher 1\n",
    "\n",
    "Before we start writing queries with PARTITION BY ORDER BY, let's quickly revise queries with PARTITION BY alone. Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  city,\n",
    "  rating,\n",
    "  AVG(rating) OVER(PARTITION BY country)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "In the above query, we show the rating of each store plus the average rating calculated for the respective country. If we hadn't used PARTITION BY country, we would have ended up with an average across all stores. \n",
    "\n",
    "This way, we get separate average values for each country.\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "For each sales row, show the store_id, day, revenue on that day and the average revenue in that store.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  AVG(revenue) OVER(PARTITION BY store_id)\n",
    "FROM sales;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more exercise and we move on to PARTITION BY ORDER BY.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "For each sales row between August 1 and August 7, 2016, show the store_id, day, number of transactions, the total number of transactions on that day in any store and the ratio of the two last columns shown as percentage rounded to integer values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  transactions,\n",
    "  SUM(transactions) OVER(PARTITION BY day),\n",
    "  ROUND(transactions::numeric / SUM(transactions) OVER(PARTITION BY day)*100)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-01' AND '2016-08-07';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANK() with PARTITION BY ORDER BY\n",
    "\n",
    "Ok! We'll introduce the features chronologically. \n",
    "\n",
    "Previously, you learned ranking functions. \n",
    "\n",
    "They are one of the places where you can apply PARTITION BY and ORDER BY together.\n",
    "\n",
    "So far, all the rankings we calculated were performed for all the rows from the query result. With that knowledge, we could have calculated the position of each store in the global network based on their ratings:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  country,\n",
    "  city,\n",
    "  rating,\n",
    "  RANK() OVER(ORDER BY rating DESC)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "Now, we can add PARTITION BY to calculate the positions independently for each country:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  country,\n",
    "  city,\n",
    "  rating,\n",
    "  RANK() OVER(PARTITION BY country ORDER BY rating DESC)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "\n",
    "In this way, we create a separate ranking for each country, so Paris and Frankfurt can both get rank = 1 for the separate rankings in France and Germany.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Take into account the period between August 10 and August 14, 2016. \n",
    "\n",
    "For each row of sales, show the following information: store_id, day, number of customers and the rank based on the number of customers in the particular store (in descending order).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  customers,\n",
    "  RANK() OVER (PARTITION BY store_id ORDER BY customers DESC)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-10' AND '2016-08-14';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTILE(x) with PARTITION BY ORDER BY\n",
    "\n",
    "Of course, you can use any other ranking function in the same way:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  country,\n",
    "  city,\n",
    "  rating,\n",
    "  NTILE(2) OVER(PARTITION BY country ORDER BY opening_day)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "In the above query, the stores are divided into two groups: older and more recent stores. \n",
    "\n",
    "These groups are created separately for each country.\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Take the sales between August 1 and August 10, 2016. For each row, show the store_id, the day, the revenue on that day and quartile number (quartile means we divide the rows into four groups) based on the revenue of the given store in the descending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  NTILE(4) OVER (PARTITION BY store_id ORDER BY revenue DESC)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-01' AND '2016-08-10';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTITION BY ORDER BY in CTE\n",
    "\n",
    "We very briefly looked at queries that introduced WITH, these are called CTEs. We haven't learned these indepth yet, so this is a little preview.\n",
    "\n",
    "We can use them to find the row with a certain rank. Now, we can find even more rows with a certain rank, each for a different group. \n",
    "\n",
    "Take a look:\n",
    "\n",
    "```\n",
    "WITH ranking AS (\n",
    "  SELECT\n",
    "    country,\n",
    "    city,\n",
    "    RANK() OVER(PARTITION BY country ORDER BY rating DESC) AS rank\n",
    "  FROM store\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  country,\n",
    "  city\n",
    "FROM ranking\n",
    "WHERE rank = 1;\n",
    "```\n",
    "\n",
    "\n",
    "The CTE in the parentheses creates a separate ranking of stores in each country based on their rating. \n",
    "\n",
    "In the outer query, we simply return the rows with the right rank. \n",
    "\n",
    "As a result, we'll see the best store in each country.\n",
    "\n",
    "# Exercise\n",
    "For each store, show a row with three columns: store_id, the revenue on the best day in that store in terms of the revenue and the day when that best revenue was achieved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "WITH ranking AS (\n",
    "  SELECT\n",
    "    store_id,\n",
    "    revenue,\n",
    "    day,\n",
    "    RANK() OVER(PARTITION BY store_id ORDER BY revenue DESC) AS rank\n",
    "  FROM sales\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  store_id,\n",
    "  revenue,\n",
    "  day\n",
    "FROM ranking\n",
    "WHERE rank = 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "We also got to know window frames.\n",
    "\n",
    "Can we use them together with PARTITION BY to create even more sophisticated windows? \n",
    "\n",
    "Of course we can. Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  country,\n",
    "  city,\n",
    "  opening_day,\n",
    "  rating,\n",
    "  MAX(rating) OVER(\n",
    "    PARTITION BY country\n",
    "    ORDER BY opening_day\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "In the above example, we show some information about each store and the maximal rating of any store opened up to that date (that's where we need a window frame) in the respective country (that's where we need PARTITION BY).\n",
    "\n",
    "\n",
    "# Exercise\n",
    "Show sales statistics between August 1 and August 7, 2016. For each row, show store_id, day, revenue and the best revenue in the respective store up to that date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  MAX(revenue) OVER(\n",
    "    PARTITION BY store_id\n",
    "    ORDER BY day\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-01' AND '2016-08-07';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Take sales from the period between August 1 and August 10, 2016. For each row, show the following information: store_id, day, number of transactions and the average number of transactions in the respective store in the window frame starting 2 days before and ending 2 days later with respect to the current row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  transactions,\n",
    "  AVG(transactions) OVER(\n",
    "    PARTITION BY store_id\n",
    "    ORDER BY day\n",
    "    ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-01' AND '2016-08-10';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAD() with PARTITION BY ORDER BY\n",
    "\n",
    "Now, let's talk about the use of analytical functions with PARTITION BY ORDER BY. \n",
    "\n",
    "Take a look at the following example:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  city,\n",
    "  opening_day,\n",
    "  LEAD(city, 1, 'NaN') OVER(PARTITION BY country ORDER BY opening_day)\n",
    "FROM store;\n",
    "```\n",
    "In the above example, we show the country, city and opening_day of each store, but we also show the city where the next store was opened – in the same country, of course.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "For each store, show the sales in the period between August 5, 2016 and August 10, 2016: store_id, day, number of transactions, number of transactions on the previous day and the difference between these two values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  transactions,\n",
    "  LAG(transactions) OVER(PARTITION BY store_id ORDER BY day),\n",
    "  transactions - LAG(transactions) OVER(PARTITION BY store_id ORDER BY day)\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-05' AND '2016-08-10';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST_VALUE() with PARTITION BY ORDER BY\n",
    "\n",
    "Of course, other analytical functions are possible as well. Let's analyze another example:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  city,\n",
    "  rating,\n",
    "  FIRST_VALUE(city) OVER(PARTITION BY country ORDER BY rating DESC)\n",
    "FROM store;\n",
    "```\n",
    "\n",
    "In the above query, we're showing each store individually, but we also show the name of the city with the highest rating in that particular country. \n",
    "\n",
    "Note that this would be impossible without PARTITION BY – we couldn't get individual city names for each country separately.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Show sales figures in the period between August 1 and August 3: for each store, show the store_id, the day, the revenue and the date with the best revenue in that period as best_revenue_day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  FIRST_VALUE(day) OVER(PARTITION BY store_id ORDER BY revenue DESC) AS best_revenue_day\n",
    "FROM sales\n",
    "WHERE day BETWEEN '2016-08-01' AND '2016-08-03';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to review what we've learned in this part:\n",
    "\n",
    "You can use PARTITION BY ORDER BY to create rankings and do row-level analytics independently for each partition in a single SQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Functions - Evaluation Order\n",
    "\n",
    "We'll compare window functions with other elements of SELECT queries. You'll find out how to use window functions in various parts of the query and where you're not allowed to do so. \n",
    "\n",
    "Are you ready?\n",
    "\n",
    "\n",
    "# Query evaluation order – problems with WHERE\n",
    "\n",
    "Great, now we can get down to work.\n",
    "\n",
    "If you recall, we said that you can't use window functions in the WHERE clause.\n",
    "\n",
    "Why is that so? \n",
    "\n",
    "Because all query elements are processed in a very strict order:\n",
    "\n",
    "- FROM – the database gets the data from tables in FROM clause and if necessary performs the JOINs,\n",
    "\n",
    "- WHERE – the data are filtered with conditions specified in WHERE clause,\n",
    "\n",
    "- GROUP BY – the data are grouped by with conditions specified in WHERE clause,\n",
    "\n",
    "- aggregate functions – the aggregate functions are applied to the groups created in the GROUP BY phase,\n",
    "\n",
    "- HAVING – the groups are filtered with the given condition, window functions,\n",
    "\n",
    "- SELECT – the database selects the given columns,\n",
    "\n",
    "- DISTINCT – repeated values are removed,\n",
    "\n",
    "- UNION/INTERSECT/EXCEPT – the database applies set operations,\n",
    "\n",
    "- ORDER BY – the results are sorted,\n",
    "\n",
    "- OFFSET – the first rows are skipped,\n",
    "\n",
    "- LIMIT/FETCH/TOP – only the first rows are selected\n",
    "\n",
    "Practically, this order means that you can't put window functions anywhere in the FROM, WHERE, GROUP BY or HAVING clauses. \n",
    "\n",
    "This is because at the time of calculating these elements, window functions are not yet calculated – and it's impossible to use something which is not already available.\n",
    "\n",
    "\n",
    "- Window functions can only appear in the SELECT and ORDER BY clauses.\n",
    "\n",
    "- If you need window functions in other parts of the query, use a subquery.\n",
    "\n",
    "- If the query uses aggregates or GROUP BY, remember that the window function can only see the grouped rows instead of the original table rows.\n",
    "\n",
    "# Subqueries for problems with WHERE\n",
    "\n",
    "\n",
    "Find out for yourself that window functions don't work in the WHERE clause. Look at the template: we would like to show some information for those auctions which have their final_price higher than the average final_price.\n",
    "\n",
    "```\n",
    "SELECT \n",
    "  id, \n",
    "  final_price \n",
    "FROM auction \n",
    "WHERE final_price > AVG(final_price) OVER()\n",
    "```\n",
    "\n",
    "Okay. As you can see, the query did not succeed.\n",
    "\n",
    "So, how can we select some information for those auctions which had their final_price higher than the average final_price? We have to use a subquery. \n",
    "\n",
    "Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  final_price \n",
    "FROM (\n",
    "  SELECT\n",
    "    id,\n",
    "    final_price,\n",
    "    AVG(final_price) OVER() AS avg_final_price\n",
    "  FROM auction) c\n",
    "WHERE final_price > avg_final_price\n",
    "```\n",
    "In the FROM clause, we introduced a subquery where we selected both the final_price for each auction and the average final_price. Because the whole subquery is calculated before the external query, we can use avg_final_price in the external query.\n",
    "\n",
    "\n",
    "# Query evaluation order – problems with HAVING\n",
    "\n",
    "The same problem occurs when we try to use a window function in the HAVING clause.\n",
    "\n",
    "Look at the template: we would like to show those countries that have the average final price higher than the average final price from all over the world.\n",
    "\n",
    "Try to run this query:\n",
    "\n",
    "\n",
    "```\n",
    "SELECT \n",
    "  country, \n",
    "  AVG(final_price) \n",
    "FROM auction \n",
    "GROUP BY country \n",
    "HAVING AVG(final_price) > AVG(final_price) OVER ();\n",
    "```\n",
    "\n",
    "\n",
    "Just as we expected, no window functions are allowed in HAVING either. Okay, you know that the remedy is to use a subquery. \n",
    "\n",
    "Try to correct the query on your own. \n",
    "\n",
    "Don't worry if you can't, the hint will be waiting for you in case you need it.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Again, we would like to show those countries (country name and average final price) that have the average final price higher than the average price from all over the world. Correct the query by using a subquery.\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  AVG(final_price) \n",
    "FROM auction \n",
    "GROUP BY country \n",
    "HAVING AVG(final_price) > (SELECT AVG(final_price) FROM auction);\n",
    "```\n",
    "\n",
    "\n",
    "# Problems with GROUP BY\n",
    "\n",
    "\n",
    "Great. \n",
    "\n",
    "The GROUP BY clause is also calculated before window functions. This means that we can't group by the values obtained with window functions. \n",
    "\n",
    "Let's check that.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Try to run the template query:\n",
    "\n",
    "```\n",
    "SELECT \n",
    "  NTILE(4) OVER(ORDER BY views DESC) AS quartile, \n",
    "  MIN(views), \n",
    "  MAX(views) \n",
    "FROM auction \n",
    "GROUP BY NTILE(4) OVER(ORDER BY views DESC);\n",
    "```\n",
    "\n",
    "The idea is as follows: we want to divide auctions into four equal groups (quartiles) based on the number of views and show the minimal and maximal value for each group. \n",
    "\n",
    "Will this query work out?\n",
    "\n",
    "\n",
    "# Subqueries for problems with GROUP BY\n",
    "\n",
    "As anticipated, the query failed. So, what can we do to make the query work? \n",
    "\n",
    "Again, we'll use a subquery:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  quartile,\n",
    "  MIN(views),\n",
    "  MAX(views)\n",
    "FROM\n",
    "  (SELECT\n",
    "    views,\n",
    "    ntile(4) OVER(ORDER BY views DESC) AS quartile\n",
    "  FROM auction) c\n",
    "GROUP BY quartile;\n",
    "```\n",
    "\n",
    "We used the window function in the inner query, which is why we could use it for grouping in the external query.\n",
    "\n",
    "So, to sum up this section, remember the following rule: the only places where we can use window functions without having to write subqueries are the SELECT and ORDER BY clauses. \n",
    "\n",
    "In all other places you have to use subqueries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What window functions see\n",
    "\n",
    "Before, we said that window functions were calculated after the GROUP BY clause. \n",
    "\n",
    "This has a very important implication for our queries: if the query uses any aggregates, GROUP BY or HAVING, the window function sees the group rows instead of the original table rows.\n",
    "\n",
    "To get a better understanding of this phenomenon, take a look at the following example:\n",
    "\n",
    "```\n",
    "SELECT \n",
    "  category_id,\n",
    "  final_price, \n",
    "  AVG(final_price) OVER() \n",
    "FROM auction;\n",
    "```\n",
    "\n",
    "This simple query will show the id and final_price of each auction alongside the average final_price from all the auctions. \n",
    "\n",
    "Now, take a look at the modified example with grouping:\n",
    "\n",
    "```\n",
    "SELECT \n",
    "  category_id,\n",
    "  MAX(final_price), \n",
    "  AVG(final_price) OVER() \n",
    "FROM auction \n",
    "GROUP BY category_id;\n",
    "```\n",
    "\n",
    "As you can see, the query doesn't work. This is because we can't use the column final_price in the window function. Once the rows have been grouped, there is no final_price value that makes sense for all the rows together.\n",
    "\n",
    "However, let's take a look at another modification of this example:\n",
    "```\n",
    "SELECT\n",
    "  category_id,\n",
    "  MAX(final_price) AS max_final, \n",
    "  AVG(MAX(final_price)) OVER()\n",
    "FROM auction\n",
    "GROUP BY category_id;\n",
    "```\n",
    "\n",
    "As you can see, the query now succeeded because we used an aggregate function (MAX(final_price)) that was indeed available after grouping the rows. By the way, this is the only place where you can nest aggregate functions inside one another.\n",
    "\n",
    "\n",
    "The best way to correctly create queries with window functions and GROUP BY is as follows: first, create the query with GROUP BY, but without window functions. \n",
    "\n",
    "Run the query (in the database or in your head). \n",
    "\n",
    "Now, the columns you see in the result are the only columns you can use in your window functions.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Group the auctions by the country. Show the country, the minimal number of participants in an auction and the average minimal number of participants across all countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  MIN(participants),\n",
    "  AVG(MIN(participants)) OVER()\n",
    "FROM auction\n",
    "GROUP BY country;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking by an aggregate\n",
    "\n",
    "Great. As you can see, it's fairly simple to create quite advanced statistics very easily thanks to how window functions behave with GROUP BY. Let's take a look at other use cases.\n",
    "\n",
    "For instance, we may make a ranking based on an aggregate function. \n",
    "\n",
    "Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  COUNT(id),\n",
    "  RANK() OVER(ORDER BY COUNT(id) DESC)\n",
    "FROM auction\n",
    "GROUP BY country;\n",
    "```\n",
    "\n",
    "We grouped auctions with respect to the country, counted the number of auctions from each country... and then we created a ranking based on that count of auctions.\n",
    "\n",
    "Now, group the auctions based on the category. Show category_id, the sum of final prices for auctions from this category and a ranking based on that sum, with the highest sum coming first.\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  category_id,\n",
    "  SUM(final_price),\n",
    "  RANK() OVER(ORDER BY SUM(final_price) DESC)\n",
    "FROM auction\n",
    "GROUP BY category_id;\n",
    "```\n",
    "\n",
    "\n",
    "# Day-to-day deltas with GROUP BY\n",
    "\n",
    "Another thing we can do with window functions when rows are grouped are leads, lags and day-to-day deltas. \n",
    "\n",
    "Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  ended,\n",
    "  SUM(final_price) AS sum_price,\n",
    "  LAG(SUM(final_price)) OVER(ORDER BY ended)\n",
    "FROM auction\n",
    "GROUP BY ended\n",
    "ORDER BY ended;\n",
    "```\n",
    "\n",
    "The above query shows each end date with the total price of all items sold on that day and the same total price on the previous day.\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "For each end day, show the following columns:\n",
    "\n",
    "- ended,\n",
    "- the sum of views from auctions that ended on that day,\n",
    "- the sum of views from the previous day (name the column previous_day,\n",
    "- delta – the difference between the sum of views on that day and on the previous day (name the column delta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  ended,\n",
    "  SUM(views),\n",
    "  LAG(SUM(views)) OVER(ORDER BY ended) AS previous_day,\n",
    "  SUM(views) - LAG(SUM(views)) OVER(ORDER BY ended) AS delta \n",
    "FROM auction\n",
    "GROUP BY ended\n",
    "ORDER BY ended;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped rows, window functions and PARTITION BY\n",
    "\n",
    "\n",
    "Finally, you can use window functions with PARTITION BY on grouped rows. One thing you need to remember is that the window function will only see grouped rows, not the original rows. Take a look:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  country,\n",
    "  ended,\n",
    "  SUM(views) AS views_on_day,\n",
    "  SUM(SUM(views)) OVER(PARTITION BY country)\n",
    "    AS views_country\n",
    "FROM auction\n",
    "GROUP BY country, ended\n",
    "ORDER BY country, ended;\n",
    "```\n",
    "\n",
    "The query might require a bit of explanation. \n",
    "\n",
    "First of all, we grouped all rows by the country and ended. \n",
    "\n",
    "Then, we showed the country name and date when the auctions ended.\n",
    "\n",
    "Look what happens in the next two columns. \n",
    "\n",
    "First, we simply sum the views in accordance with our GROUP BY clause, i.e. we get the sum of views in all auctions from the particular country on the particular day. \n",
    "\n",
    "But look what happens next. We use a window function to sum all daily sums for a particular country. \n",
    "\n",
    "As a result, we get the sum of views for a particular country on all days.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Group all auctions by the category and end date and show the following columns:\n",
    "\n",
    "- category_id,\n",
    "- ended,\n",
    "- the average daily final price as daily_avg_final_price in that category on that day,\n",
    "- the maximal daily average in that category from any day as daily_max_avg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT  \n",
    "  category_id,  \n",
    "  ended,  \n",
    "  AVG(final_price) AS daily_avg_final_price,\n",
    "  MAX(AVG(final_price)) OVER(PARTITION BY category_id) AS daily_max_avg \n",
    "FROM auction\n",
    "GROUP BY category_id, ended\n",
    "ORDER BY category_id, ended;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Excellent. It's time to wrap things up.\n",
    "\n",
    "- Window functions can only appear in the SELECT and ORDER BY clauses.\n",
    "\n",
    "- If you need window functions in other parts of the query, use a subquery.\n",
    "\n",
    "- If the query uses aggregates or GROUP BY, remember that the window function can only see the grouped rows instead of the original table rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Use the same fiddle from class.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Let's analyze sales data between August 1 and August 3, 2016. For each row, show store_id, day, transactions and the ranking of the store on that day in terms of the number of transactions as compared to other stores. \n",
    "\n",
    "The store with the greatest number should get 1 from a window function. \n",
    "\n",
    "Use individual row ranks even when two rows share the same value. Name the column place_no.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  transactions,\n",
    "  ROW_NUMBER() OVER (PARTITION BY day ORDER BY transactions DESC) AS place_no\n",
    "FROM sales\n",
    "WHERE day\n",
    "BETWEEN '2016-08-01' AND '2016-08-03';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "For each day of the sales statistics, show the day, the store_id of the best store in terms of the revenue on that day, and that revenue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "WITH ranking AS (\n",
    "  SELECT\n",
    "    store_id,\n",
    "    day,\n",
    "    revenue,\n",
    "    RANK() OVER(PARTITION BY day ORDER BY revenue DESC) AS rank\n",
    "  FROM sales\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue\n",
    "FROM ranking\n",
    "WHERE rank = 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Divide the sales results for each store into four groups based on the number of transactions and for each store, show the rows in the group with the lowest numbers of transactions: store_id, day, transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "WITH ranking AS (\n",
    "  SELECT\n",
    "    store_id,\n",
    "    day,\n",
    "    transactions,\n",
    "    NTILE(4) OVER(PARTITION BY store_id ORDER BY transactions) AS quartile\n",
    "  FROM sales\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  transactions\n",
    "FROM ranking\n",
    "WHERE quartile = 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "For each sales row, show the following information: store_id, day, revenue and the future cash flow receivable by the headquarters (i.e. the total revenue in that store, counted from the current day until the last day in our table).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  SUM(revenue) OVER(\n",
    "    PARTITION BY store_id\n",
    "    ORDER BY day\n",
    "    ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n",
    "FROM sales\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "For each row of the sales figures, show the following information: store_id, day, revenue, revenue a week before and the ratio of revenue today to the revenue a week before expressed in percentage with 2 decimal places.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  revenue,\n",
    "  LAG(revenue,7) OVER(PARTITION BY store_id ORDER BY day),\n",
    "  ROUND(revenue / LAG(revenue, 7) OVER(PARTITION BY store_id ORDER BY day) * 100, 2)\n",
    "FROM sales;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "For each row, show the following columns: store_id, day, customers and the number of clients in the 5th greatest store in terms of the number of customers on that day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  store_id,\n",
    "  day,\n",
    "  customers,\n",
    "  NTH_VALUE(customers, 5) OVER(\n",
    "    PARTITION BY day\n",
    "    ORDER BY customers DESC\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n",
    "FROM sales;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Find the id, country and views for those auctions where the number of views was below the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  id,\n",
    "  country,\n",
    "  views\n",
    "FROM (\n",
    "  SELECT\n",
    "    id,\n",
    "    country,\n",
    "    views,\n",
    "    AVG(views) OVER() AS avg_views\n",
    "  FROM auction) c\n",
    "WHERE views < avg_views;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Now, divide all auctions into 6 equal groups based on the asking_price in ascending order. \n",
    "\n",
    "Show columns group_no, minimal, average and maximal value for that group. Sort by the group in ascending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  group_no,\n",
    "  MIN(asking_price),\n",
    "  AVG(asking_price),\n",
    "  MAX(asking_price)\n",
    "FROM (\n",
    "  SELECT\n",
    "    asking_price,\n",
    "    NTILE(6) OVER(ORDER BY asking_price) AS group_no\n",
    "  FROM auction) c\n",
    "GROUP BY group_no\n",
    "ORDER BY group_no;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Group the auctions by category_id and show the category_id and maximal asking price in that category alongside the average maximal price across all categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "SELECT\n",
    "  category_id,\n",
    "  MAX(asking_price),\n",
    "  AVG(MAX(asking_price)) OVER() \n",
    "FROM auction\n",
    "GROUP BY category_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
